# Copy to `.env` (or source it) and fill in as needed.
# Note: Default installs should work without any API keys (tests use MockLM).

# -----------------------------------------------------------------------------
# OpenAI (or OpenAI-compatible local runners)
# -----------------------------------------------------------------------------
# For OpenAI: set a real key.
# For local runners (Ollama/LM Studio/Docker Model Runner): many setups accept a
# dummy key, but still require the variable to be present.
OPENAI_API_KEY="your-openai-key-or-dummy"

# Model to use for OpenAI API calls.
# Examples: gpt-4o, gpt-4o-mini, gpt-4-turbo, gpt-3.5-turbo
# For local runners: llama3.2, mistral, phi3, etc.
OPENAI_MODEL="gpt-4o-mini"

# Optional: point the OpenAI client at a local runner that speaks OpenAI API.
# Examples (vary by tool):
# - Ollama (with OpenAI-compatible endpoint): http://localhost:11434/v1
# - LM Studio:                               http://localhost:1234/v1
# - Docker Model Runner:                     http://localhost:8000/v1
OPENAI_BASE_URL="http://localhost:11434/v1"

# -----------------------------------------------------------------------------
# Anthropic
# -----------------------------------------------------------------------------
ANTHROPIC_API_KEY="your-anthropic-key"

# -----------------------------------------------------------------------------
# Google Gemini (google-genai)
# -----------------------------------------------------------------------------
GOOGLE_API_KEY="your-google-api-key"

# -----------------------------------------------------------------------------
# Portkey
# -----------------------------------------------------------------------------
PORTKEY_API_KEY="your-portkey-key"

# -----------------------------------------------------------------------------
# LiteLLM (if/when used)
# -----------------------------------------------------------------------------
# LITELLM_API_KEY="your-key"
# LITELLM_BASE_URL="http://localhost:4000"
